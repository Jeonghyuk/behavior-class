{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tested on\n",
    "# Python 3.5.3 :: Anaconda 4.4.0 (64-bit)\n",
    "# scipy 0.19.1\n",
    "# keras 2.0.6 <- not required to reproduce the result of Fig. 1-2 of our paper.\n",
    "# tensorflow-gpu 1.2.1 <- not required to reproduce the result of Fig. 1-2 of our paper.\n",
    "# numpy 1.13.1\n",
    "# pylab using matplotlib backend: Qt5Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STEP 1-1. \n",
    "## Define scripts\n",
    "\n",
    "\n",
    "## Preprocessing ##\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def smoothing(dat_, bin_=16):\n",
    "    # Calculate F/DeltaF from signal\n",
    "    buffer = np.zeros(len(dat_) - bin_)\n",
    "    for num in range(len(dat_)-bin_):\n",
    "        buffer[num] = (dat_[num+bin_] / dat_[num:num+bin_].mean())-1\n",
    "    return (buffer * (buffer>0) * (buffer<2))/2 + (2 * (buffer>=2))\n",
    "\n",
    "def preprocessing(path):\n",
    "    # Calculate 255 * F_norm for converting 8 bit integer\n",
    "    with open(path, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        labels = next(spamreader)\n",
    "        data_original = np.array([row for row in spamreader], dtype=float).T\n",
    "        data_smoothed = np.array([255*smoothing(elem) for elem in data_original])\n",
    "    data_normalized = np.array([255*(elem-min(elem))/(max(elem)-min(elem)) for elem in data_smoothed])\n",
    "    # Reduce dimension from 18 to 9\n",
    "    data_preprocessed = []\n",
    "    for num in range(9):\n",
    "        data_preprocessed.append(np.maximum(data_normalized[num], data_normalized[17-num]))\n",
    "    return np.asarray(data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "## STEP 1-2\n",
    "## Import data and preprocessing\n",
    "\n",
    "data_pre = []\n",
    "data_path = ['/csv/No01.csv',\n",
    "             '/csv/No02.csv',\n",
    "             '/csv/No03.csv',\n",
    "             '/csv/No04.csv',\n",
    "             '/csv/No05.csv',\n",
    "             '/csv/No06.csv',\n",
    "             '/csv/No07.csv',\n",
    "             '/csv/No08.csv',\n",
    "             '/csv/No09.csv',\n",
    "             '/csv/No10.csv',\n",
    "             '/csv/No11.csv',\n",
    "             '/csv/No12.csv']\n",
    "for path in tqdm(data_path):\n",
    "    data_pre.append(preprocessing(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2-1\n",
    "## Go to STEP 2-3 if you cannot use Keras.\n",
    "\n",
    "## Import Keras (important note : use TensorFlow backend)\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "## Import Imagnet pre-trained VGG16 ##\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(72,72,3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_conv3').output)\n",
    "\n",
    "## Feature Extraction from RGB images##\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "def feature_extraction(data, window_size):\n",
    "    buffer = []\n",
    "    data_len = len(data)\n",
    "    for num in tqdm(range(len(data[0])-window_size)):\n",
    "        image_pre = np.uint8(data[:,num:num+window_size])\n",
    "        image_channel = cv2.merge((image_pre,image_pre,image_pre))\n",
    "        image_input = cv2.resize(image_channel, (0,0), fx=(72/window_size), fy=(72/data_len))\n",
    "        Conv4_3 = model.predict(np.expand_dims(image_input, axis=0))\n",
    "        GAP = Conv4_3.mean(axis=1).mean(axis=1)[0]\n",
    "        buffer.append(GAP)\n",
    "    return np.asarray(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2024/2024 [02:01<00:00, 16.61it/s]\n",
      "100%|██████████| 2024/2024 [01:57<00:00, 17.63it/s]\n",
      "100%|██████████| 2024/2024 [01:58<00:00, 17.14it/s]\n",
      "100%|██████████| 2024/2024 [01:58<00:00, 17.23it/s]\n",
      "100%|██████████| 2024/2024 [01:58<00:00, 16.50it/s]\n",
      "100%|██████████| 2024/2024 [01:57<00:00, 17.36it/s]\n",
      "100%|██████████| 2024/2024 [01:57<00:00, 17.58it/s]\n",
      "100%|██████████| 2024/2024 [02:06<00:00, 17.28it/s]\n",
      "100%|██████████| 2024/2024 [02:04<00:00, 16.21it/s]\n",
      "100%|██████████| 2024/2024 [02:00<00:00, 16.79it/s]\n",
      "100%|██████████| 2024/2024 [02:00<00:00, 17.29it/s]\n",
      "100%|██████████| 2024/2024 [02:10<00:00, 15.55it/s]\n"
     ]
    }
   ],
   "source": [
    "## STEP 2-2\n",
    "## Extract global average pooled value (GAP) from VGG16 Conv4_3\n",
    "\n",
    "vgg = np.zeros((0,512), dtype=float32)\n",
    "for ind in range(len(data_pre)):\n",
    "    vgg = np.append(vgg, feature_extraction(data_pre[ind], 8), axis=0)\n",
    "    \n",
    "# calculation time < 30 min.\n",
    "# If you want to shorten the calculation time, use multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2-3\n",
    "## Import calculated data which used in our paper.\n",
    "import pickle\n",
    "with (open('/pickle/Fig1vgg16_00.pickle', \"rb\" )) as openfile:\n",
    "    vgg_used_00 = pickle.load(openfile)\n",
    "with (open('/pickle/Fig1vgg16_01.pickle', \"rb\" )) as openfile:\n",
    "    vgg_used_01 = pickle.load(openfile)\n",
    "vgg_used = np.append(vgg_used_00, vgg_used_01, axis=0)\n",
    "## If you skipped STEP 2-1 and 2-2, you can use vgg_used as vgg (vgg = vgg_used.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same datatype = True\n",
      "Checksum = True\n"
     ]
    }
   ],
   "source": [
    "## STEP 2-4 (Check)\n",
    "\n",
    "## Check datatype\n",
    "print('Same datatype =', vgg_used.dtype == vgg.dtype)\n",
    "\n",
    "## Checksum\n",
    "print('Checksum =', abs((vgg_used - vgg)).sum() == 0)\n",
    "\n",
    "## The checksum must be 0.0\n",
    "## If they are not true, clustering result may differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STEP 3-1\n",
    "## Hierarchical Clustering using Ward's method\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\n",
    "\n",
    "Z = linkage(vgg, 'ward')\n",
    "c, coph_dists = cophenet(Z, pdist(vgg))\n",
    "\n",
    "# Calculation time < 10 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 3-2\n",
    "## Get cluster label \n",
    "\n",
    "max_d = 5000\n",
    "cluster = fcluster(Z, max_d, criterion='distance')\n",
    "\n",
    "#Use max_d = 5000 to reproduce our result.\n",
    "#Adjust max_d if you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 3-3\n",
    "## Match the cluster label and signal data\n",
    "\n",
    "buffer = np.zeros(0)\n",
    "data_tot = len(data_pre)\n",
    "window_size = 8\n",
    "data_len = len(data_pre[0][0]) - window_size\n",
    "\n",
    "for num in range(data_tot):\n",
    "    buffer = np.append(buffer, np.zeros((window_size//2)))\n",
    "    buffer = np.append(buffer, cluster[data_len*num:data_len*(num+1)])\n",
    "    buffer = np.append(buffer, np.zeros((window_size//2 + window_size%2)))\n",
    "clusters_comp = buffer.copy()\n",
    "\n",
    "buffer = np.zeros((9,0))\n",
    "for ind in range(data_tot):\n",
    "    buffer = np.append(buffer, data_pre[ind], axis=1)\n",
    "data_pre_comp = buffer.copy()\n",
    "\n",
    "buffer = np.zeros(0)\n",
    "for num in range(data_tot):\n",
    "    buffer = np.append(buffer, cluster[data_len*num:data_len*(num+1)])\n",
    "    buffer = np.append(buffer, np.zeros(window_size))\n",
    "clusters_matched = buffer.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STEP 3-4\n",
    "## post-hoc human labeling using average image of cluster\n",
    "\n",
    "def cluster_mean_image(dat, num_clust, window_size=8):\n",
    "    temp = []\n",
    "    for num in range(len(dat)):\n",
    "        if dat[num] == num_clust:\n",
    "            temp.append(data_pre_comp[:, num:num+window_size])\n",
    "    return np.mean(np.asarray(temp), axis=0)\n",
    "\n",
    "f, axarr = plt.subplots(1,int(max(clusters_matched)), sharex=True, frameon=False)\n",
    "for num in range(int(max(clusters_matched))):\n",
    "    axarr[num].imshow(cluster_mean_image(clusters_matched, num+1)/255, aspect='auto', vmin=0, vmax=.5, cmap='Greys_r')\n",
    "    axarr[num].set_xlabel(num+1)\n",
    "    axarr[num].set_yticklabels([])\n",
    "    axarr[num].set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efdc802a390>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STEP 3-5\n",
    "## Get activity data and final check\n",
    "\n",
    "AT = np.zeros(len(clusters_matched))\n",
    "BW = np.zeros(len(clusters_matched))\n",
    "FW = np.zeros(len(clusters_matched))\n",
    "PT = np.zeros(len(clusters_matched))\n",
    "QS = np.zeros(len(clusters_matched))\n",
    "\n",
    "for num in [19,20,21,22,23]:\n",
    "    AT += (clusters_comp == num)\n",
    "for num in [4,5,6]:\n",
    "    BW += (clusters_comp == num)\n",
    "for num in [15,16]:\n",
    "    FW += (clusters_comp == num)\n",
    "for num in [11,12,13]:\n",
    "    PT += (clusters_comp == num)\n",
    "for num in [1]:\n",
    "    QS += (clusters_comp == num)\n",
    "\n",
    "f, axarr = plt.subplots(2, sharex=True)\n",
    "axarr[0].imshow(data_pre_comp/255, cmap='Greys_r', vmin=0, vmax=1, aspect='auto')\n",
    "axarr[1].plot(1.0 * AT, c='purple')\n",
    "axarr[1].plot(0.8 * BW, c='red')\n",
    "axarr[1].plot(0.6 * FW, c='blue')\n",
    "axarr[1].plot(0.4 * PT, c='green')\n",
    "axarr[1].plot(0.2 * QS, c='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## STEP 3-6 (Check)\n",
    "## Compare labeled activity and data which we used in Fig. 1-2 of our paper.\n",
    "\n",
    "import pickle\n",
    "with (open('/pickle/Fig1acts.pickle', \"rb\" )) as openfile:\n",
    "    acts_used = pickle.load(openfile)\n",
    "\n",
    "acts = [AT, BW, FW, PT, QS]\n",
    "for ind in range(len(acts)):\n",
    "    print(abs(acts[ind]-acts_used[ind]).sum() == 0)\n",
    "    \n",
    "## print True 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GROUND TRUTH\n",
    "\n",
    "import pickle\n",
    "with (open('/pickle/Fig1groundtruth.pickle', \"rb\" )) as openfile:\n",
    "    ground_truth = pickle.load(openfile)\n",
    "\n",
    "#the value of ground_truth data\n",
    "#1 = AT, 0.8 = BW, 0.6 = FW, 0.4 = PT\n",
    "# [0:400] of ground_truth = [816:1216] of sample 1\n",
    "# [400:800] of ground_truth = [816:1216] of sample 2, and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efdb7e7c9b0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check GROUND TRUTH using sample 1.\n",
    "\n",
    "f, axarr = plt.subplots(3, sharex=True)\n",
    "axarr[0].imshow(data_pre_comp[:,816:1216]/255, cmap='Greys_r', vmin=0, vmax=1, aspect='auto')\n",
    "axarr[1].plot(1.0 * AT[816:1216], c='purple')\n",
    "axarr[1].plot(0.8 * BW[816:1216], c='red')\n",
    "axarr[1].plot(0.6 * FW[816:1216], c='blue')\n",
    "axarr[1].plot(0.4 * PT[816:1216], c='green')\n",
    "axarr[1].plot(0.2 * QS[816:1216], c='grey')\n",
    "axarr[2].plot(1.0 * (ground_truth==1)[0:400], c='purple')\n",
    "axarr[2].plot(0.8 * (ground_truth==.8)[0:400], c='red')\n",
    "axarr[2].plot(0.6 * (ground_truth==.6)[0:400], c='blue')\n",
    "axarr[2].plot(0.4 * (ground_truth==.4)[0:400], c='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
